{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7161c2d7-ed73-46b7-bac4-37b49e74b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_16440\\272843287.py:2: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "What\n",
      " \n",
      "degree\n",
      " \n",
      "is\n",
      " \n",
      "Tejas\n",
      " \n",
      "Gaikwad\n",
      " \n",
      "currently\n",
      " \n",
      "pursuing?\n",
      " \n",
      "Master\n",
      " \n",
      "of\n",
      " \n",
      "Science\n",
      " \n",
      "in\n",
      " \n",
      "Computer\n",
      " \n",
      "Science\n",
      " \n",
      "at\n",
      " \n",
      "the\n",
      " \n",
      "State\n",
      " \n",
      "University\n",
      " \n",
      "of\n",
      " \n",
      "New\n",
      " \n",
      "York\n",
      " \n",
      "at\n",
      " \n",
      "Buffalo.\n",
      " \n",
      "Which\n",
      " \n",
      "courses\n",
      " \n",
      "has\n",
      " \n",
      "Tejas\n",
      " \n",
      "completed\n",
      " \n",
      "during\n",
      " \n",
      "his\n",
      " \n",
      "master's\n",
      " \n",
      "program?\n",
      " \n",
      "Machine\n",
      " \n",
      "Learning,\n",
      " \n",
      "Analysis\n",
      " \n",
      "of\n",
      " \n",
      "Algorithms,\n",
      " \n",
      "Data\n",
      " \n",
      "Intensive\n",
      " \n",
      "Computing,\n",
      " \n",
      "and\n",
      " \n",
      "Computer\n",
      " \n",
      "Security.\n",
      " \n",
      "Where\n",
      " \n",
      "did\n",
      " \n",
      "Tejas\n",
      " \n",
      "complete\n",
      " \n",
      "his\n",
      " \n",
      "undergraduate\n",
      " \n",
      "studies?\n",
      " \n",
      "Vishwakarma\n",
      " \n",
      "Institute\n",
      " \n",
      "of\n",
      " \n",
      "Technology\n",
      " \n",
      "in\n",
      " \n",
      "Pune,\n",
      " \n",
      "Indi\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract data\n",
    "pdf_text = extract_text_from_pdf(\"data.pdf\")\n",
    "print(pdf_text[:500])  # Print first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c37e979-84ff-4822-a1b7-f321a856ef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 55\n",
      "[\"What\\n \\ndegree\\n \\nis\\n \\nTejas\\n \\nGaikwad\\n \\ncurrently\\n \\npursuing?\\n \\nMaster\\n \\nof\\n \\nScience\\n \\nin\\n \\nComputer\\n \\nScience\\n \\nat\\n \\nthe\\n \\nState\\n \\nUniversity\\n \\nof\\n \\nNew\\n \\nYork\\n \\nat\\n \\nBuffalo.\\n \\nWhich\\n \\ncourses\\n \\nhas\\n \\nTejas\\n \\ncompleted\\n \\nduring\\n \\nhis\\n \\nmaster's\\n \\nprogram?\\n \\nMachine\\n \\nLearning,\\n \\nAnalysis\\n \\nof\\n \\nAlgorithms,\\n \\nData\\n \\nIntensive\\n \\nComputing,\\n \\nand\\n \\nComputer\\n \\nSecurity.\\n \\nWhere\\n \\ndid\\n \\nTejas\\n \\ncomplete\\n \\nhis\\n \\nundergraduate\\n \\nstudies?\\n \\nVishwakarma\\n \\nInstitute\\n \\nof\\n \\nTechnology\\n \\nin\\n \\nPune,\", \"his\\n \\nundergraduate\\n \\nstudies?\\n \\nVishwakarma\\n \\nInstitute\\n \\nof\\n \\nTechnology\\n \\nin\\n \\nPune,\\n \\nIndia.\\n \\nWhat\\n \\nwas\\n \\nTejas's\\n \\nmajor\\n \\nduring\\n \\nhis\\n \\nbachelor's\\n \\ndegree?\\n \\nElectronics\\n \\nand\\n \\nTelecommunication\\n \\nEngineering.\\n \\nWhich\\n \\nprogramming\\n \\nlanguages\\n \\nis\\n \\nTejas\\n \\nproficient\\n \\nin?\\n \\nPython,\\n \\nR,\\n \\nC++,\\n \\nGo,\\n \\nSQL\\n \\n(Postgres),\\n \\nJavaScript,\\n \\nand\\n \\nHTML/CSS.\\n \\nWhat\\n \\nframeworks\\n \\nhas\\n \\nTejas\\n \\nworked\\n \\nwith?\\n \\nReact,\\n \\nNode.js,\\n \\nFlask,\\n \\nFastAPI,\\n \\nSpring\\n \\nBoot,\\n \\nSpark,\\n \\nHadoop,\"]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_text(text, chunk_size=500, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# Split the extracted text into chunks\n",
    "chunks = split_text(pdf_text)\n",
    "print(f\"Total Chunks: {len(chunks)}\")\n",
    "print(chunks[:2])  # Print first two chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c3009fb-65a9-40a0-af29-03908916adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.27.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.3.33)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-huggingface) (3.4.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.48.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (8.2.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.0)\n",
      "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-huggingface\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32042dc3-e32e-4028-ab96-fedcf5f16316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Load DeepSeek embeddings model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "# Convert text chunks into embeddings\n",
    "embeddings = np.array([embedding_model.embed_query(chunk) for chunk in chunks])\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]  # Get the embedding dimension\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index\n",
    "faiss.write_index(index, \"faiss_index.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9efabeef-7f95-4cc3-ac37-6b0468741a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Text: [\"his\\n \\nundergraduate\\n \\nstudies?\\n \\nVishwakarma\\n \\nInstitute\\n \\nof\\n \\nTechnology\\n \\nin\\n \\nPune,\\n \\nIndia.\\n \\nWhat\\n \\nwas\\n \\nTejas's\\n \\nmajor\\n \\nduring\\n \\nhis\\n \\nbachelor's\\n \\ndegree?\\n \\nElectronics\\n \\nand\\n \\nTelecommunication\\n \\nEngineering.\\n \\nWhich\\n \\nprogramming\\n \\nlanguages\\n \\nis\\n \\nTejas\\n \\nproficient\\n \\nin?\\n \\nPython,\\n \\nR,\\n \\nC++,\\n \\nGo,\\n \\nSQL\\n \\n(Postgres),\\n \\nJavaScript,\\n \\nand\\n \\nHTML/CSS.\\n \\nWhat\\n \\nframeworks\\n \\nhas\\n \\nTejas\\n \\nworked\\n \\nwith?\\n \\nReact,\\n \\nNode.js,\\n \\nFlask,\\n \\nFastAPI,\\n \\nSpring\\n \\nBoot,\\n \\nSpark,\\n \\nHadoop,\", \"What\\n \\ndegree\\n \\nis\\n \\nTejas\\n \\nGaikwad\\n \\ncurrently\\n \\npursuing?\\n \\nMaster\\n \\nof\\n \\nScience\\n \\nin\\n \\nComputer\\n \\nScience\\n \\nat\\n \\nthe\\n \\nState\\n \\nUniversity\\n \\nof\\n \\nNew\\n \\nYork\\n \\nat\\n \\nBuffalo.\\n \\nWhich\\n \\ncourses\\n \\nhas\\n \\nTejas\\n \\ncompleted\\n \\nduring\\n \\nhis\\n \\nmaster's\\n \\nprogram?\\n \\nMachine\\n \\nLearning,\\n \\nAnalysis\\n \\nof\\n \\nAlgorithms,\\n \\nData\\n \\nIntensive\\n \\nComputing,\\n \\nand\\n \\nComputer\\n \\nSecurity.\\n \\nWhere\\n \\ndid\\n \\nTejas\\n \\ncomplete\\n \\nhis\\n \\nundergraduate\\n \\nstudies?\\n \\nVishwakarma\\n \\nInstitute\\n \\nof\\n \\nTechnology\\n \\nin\\n \\nPune,\", 'studies\\n \\nin?\\n \\nPune,\\n \\nIndia\\n \\nWhich\\n \\ninstitute\\n \\ndid\\n \\nTejas\\n \\nattend\\n \\nfor\\n \\nan\\n \\nadditional\\n \\nBachelor\\n \\nof\\n \\nScience\\n \\ndegree?\\n \\nIndian\\n \\nInstitute\\n \\nof\\n \\nTechnology\\n \\n(IIT)\\n \\nMadras\\n \\nWhat\\n \\nwas\\n \\nTejas’s\\n \\nGPA\\n \\nin\\n \\nhis\\n \\nIIT\\n \\nMadras\\n \\nprogram?\\n \\n8/10.0\\n \\nWhat\\n \\nwas\\n \\nTejas’s\\n \\nCGPA\\n \\nin\\n \\nhis\\n \\nBachelor’s\\n \\ndegree\\n \\nat\\n \\nVishwakarma\\n \\nInstitute\\n \\nof\\n \\nTechnology?\\n \\n7.93/10\\n \\nWhich\\n \\nyear\\n \\ndid\\n \\nTejas\\n \\nstart\\n \\nhis\\n \\nmaster’s\\n \\nprogram?\\n \\nFall\\n \\n2024\\n \\nWhich\\n \\nadditional\\n \\nfields']\n"
     ]
    }
   ],
   "source": [
    "def retrieve_similar_text(query, k=3):\n",
    "    query_embedding = np.array([embedding_model.embed_query(query)])\n",
    "    D, I = index.search(query_embedding, k)  # Get top k results\n",
    "    return [chunks[i] for i in I[0]]  # Retrieve corresponding text chunks\n",
    "\n",
    "# Test Retrieval\n",
    "query = \"Where did Tejas complete his undergraduate studies?\"\n",
    "retrieved_texts = retrieve_similar_text(query)\n",
    "print(\"Retrieved Text:\", retrieved_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749473f7-1790-4da0-8eb8-3aa7be9b8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# ✅ Load the latest DeepSeek model\n",
    "model_name = \"deepseek-ai/DeepSeek-R1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "def generate_response(question):\n",
    "    \"\"\"Generate response from DeepSeek-R1 with retrieved context.\"\"\"\n",
    "    # ✅ Retrieve relevant chunks for better contextual answers\n",
    "    context = retrieve_similar_text(question)\n",
    "    prompt = f\"Context:\\n{'\\n'.join(context)}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "\n",
    "    # ✅ Tokenize input with better memory handling\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ✅ Generate response efficiently\n",
    "    output = model.generate(**inputs, max_new_tokens=150, temperature=0.7, top_p=0.9)\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# ✅ Test the chatbot\n",
    "question = \"What degree is Tejas Gaikwad currently pursuing?\"\n",
    "response = generate_response(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05e6d5-8657-45f0-9744-11649df2b5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
