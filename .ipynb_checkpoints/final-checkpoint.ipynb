{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e686cdd4-5cf7-49d2-861f-d62d96440dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\tejas\\anaconda3\\lib\\site-packages (0.11.5)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\tejas\\anaconda3\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\tejas\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\tejas\\anaconda3\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pdfplumber) (10.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.48.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.6.0+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.27.1)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-groq) (0.18.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-groq) (0.3.33)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.3.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (8.2.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.7)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pdfplumber faiss-cpu sentence-transformers langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "719764d8-35c6-467b-b35f-2485b04fc9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured sections extracted: 13\n",
      "FAISS index built with 13 documents.\n",
      "=== Optimized Prompt Sent to Model ===\n",
      "\n",
      "    You are a highly factual AI assistant. Use only the provided context to answer accurately.\n",
      "    Do NOT add false information. If details are missing, state only the available data.\n",
      "    \n",
      "    Context:\n",
      "Recommendations:\n",
      "## Recommendation 1\n",
      "Recommendator's Name: Rakesh Jangam\n",
      "Recommendator's Position: Was Engineer III & Mentor to Vivek\n",
      "Recommendator's LinkedIn: https://www.linkedin.com/in/rakesh-j-87b4a7134/\n",
      "Company: University of Phoenix\n",
      "Recommendation:\n",
      "\"It has been an absolute pleasure mentoring Vivek Patel during his time as an IT intern in\n",
      "University of Phoenix. Vivek displayed a genuine eagerness to learn and grow in the field. His\n",
      "curiosity and dedication to mastering new technologies have been truly impressive. Throughout\n",
      "his internship, he consistently demonstrated a proactive approach to learning, eagerly seeking\n",
      "out challenges and opportunities to grow. He actively sought feedback, showing a genuine\n",
      "commitment to continuous improvement. I wholeheartedly recommend Vivek Patel for any future\n",
      "endeavors, confident that he will excel and make significant contributions wherever he goes.\"\n",
      "## Recommendation 2\n",
      "Recommendator's Name: Ameer Jhan\n",
      "Recommendator's Position: Was Tech Lead & Mentor to Vivek\n",
      "Recommendator's LinkedIn: https://www.linkedin.com/in/ameerthehacker/\n",
      "Company: HackerRank\n",
      "Recommendation:\n",
      "\"Vivek is one of the most enthusiastic and trustable people I have worked with, while working\n",
      "with our team Vivek has solved many complex problems like terminal collaboration in the IDEs.\n",
      "He has also contributed cross team whenever possible. If you gave a problem for Vivek to solve\n",
      "then rest assured that he will come back with a roadmap to solve it.\n",
      "I would recommend Vivek to anyone in a heartbeat, thanks Vivek for everything you did, and all\n",
      "the very best!\"\n",
      "## Recommendation 3\n",
      "Recommendator's Name: Neel Yadav\n",
      "Recommendator's Position: Worked in same team with Vivek\n",
      "Recommendation:\n",
      "\"I am writing to recommend Vivek for any computer science-related position he may be applying\n",
      "for. I had the pleasure of working with Vivek on multiple projects during our Btech program, and I\n",
      "can confidently say that he is an exceptional team player and an asset to any team.\n",
      "Vivek possesses a strong understanding of computer science concepts and has a natural\n",
      "inclination towards problem-solving. His technical skills in programming languages such as\n",
      "Java, Python, and C++ are impressive, and he has shown a willingness to learn new\n",
      "technologies to keep up with the latest trends in the industry.\n",
      "Working with Vivek on our projects, I was particularly impressed with his attention to detail,\n",
      "analytical skills, and ability to work under pressure. He has an excellent work ethic and always\n",
      "went the extra mile to ensure that the project was completed to the best of our abilities.\n",
      "I have no doubt that Vivek will be an excellent addition to any team he joins. I strongly\n",
      "recommend him for any computer science-related position and believe that he has the potential\n",
      "to excel in any role he takes on.\"\n",
      "## Recommendation 4\n",
      "Recommendator's Name: Sahil Monpara\n",
      "Recommendator's Position: Worked in same team with Vivek\n",
      "Recommendation:\n",
      "\"Vivek is a smart, honest, and hardworking person. He lives life to the fullest still learns the best\n",
      "of the skills and gets the best of the opportunities. Studying with him is a mix of enjoyment and\n",
      "lots of learning. I must admit that he is the very best Front-end Developer and a real 'Jugadu'\n",
      "guy. You never regret working with him.\"\n",
      "\n",
      "# Vivek's Information:\n",
      "Name: Vivek Patel\n",
      "Email: vivek.p9737@gmail.com\n",
      "Current residence: Phoenix, USA\n",
      "LinkedIn: https://www.linkedin.com/in/vivek9patel\n",
      "Github: https://github.com/vivek9patel\n",
      "Portfolio Website: https://www.vivek9patel.com\n",
      "Resume link: https://www.vivek9patel.com/resume\n",
      "All projects link: https://www.vivek9patel.com/projects\n",
      "\n",
      "Hobbies:\n",
      "- Traveling\n",
      "- Hiking\n",
      "- Reading\n",
      "- Playing Chess\n",
      "- Biking\n",
      "\n",
      "Publications:\n",
      "## Publication 1\n",
      "Title: \"A Real Time Face Mask Detection-based Attendance System using MobileNetV2\"\n",
      "Journal: Springer Lecture Notes on Data Engineering and Communications Technologies\n",
      "Description: The image classification model is trained by us with the help of fine machine\n",
      "learning libraries like Tensor Flow and Keras, accompanied by MobileNetV2 neural network\n",
      "architecture. Here, live video can be taken as an input by the webcam, which later on predicts\n",
      "whether the face present in the ROI (Region of Interest) has mask or not. The system first\n",
      "detects the face of a person and then identifies whether mask is worn or not.\n",
      "Date: January 2022\n",
      "Link:\n",
      "[https://link.springer.com/chapter/10.1007/978-981-16-7610-9_49](https://link.springer.com/chap\n",
      "ter/10.1007/978-981-16-7610-9_49)\n",
      "\n",
      "Projects - listed by most favourite to least favourite:\n",
      "## Project 1\n",
      "Title: Visualizing Fabric of Ohio City\n",
      "Tagline: A Data-visualization project to highlight volunteersâ€™ characteristics, social activities, and\n",
      "predominant business base.\n",
      "Year: 2023\n",
      "Technologies: D3, Javascript, Material UI, React, Flask, Azure, Postgre\n",
      "GitHub: https://github.com/vivek9patel/CSE-578-Project-Frontend\n",
      "Demo: https://cse-578-project-frontend.vercel.app\n",
      "Category: Web Project\n",
      "## Project 2\n",
      "Title: VScode CSS Compatibility\n",
      "Tagline: A \n",
      "\n",
      "\n",
      "    Question: Can you tell me about vivek ?\n",
      "    Answer:\n",
      "    \n",
      "\n",
      "=== Generated Answer ===\n",
      "Vivek Patel is an individual with a background in computer science. He has a LinkedIn profile (https://www.linkedin.com/in/vivek9patel) and a personal website (https://www.vivek9patel.com). He has worked on various projects, including a data-visualization project called \"Visualizing Fabric of Ohio City\" and has published a research paper titled \"A Real Time Face Mask Detection-based Attendance System using MobileNetV2\". He has also received recommendations from four individuals, including Rakesh Jangam, Ameer Jhan, Neel Yadav, and Sahil Monpara, who praise his skills, work ethic, and enthusiasm. His hobbies include traveling, hiking, reading, playing chess, and biking. He is currently residing in Phoenix, USA, and his contact information is available on his website.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Configuration\n",
    "# -----------------------------\n",
    "# Set API Key\n",
    "groq_api_key = \"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\"  # <-- Replace with your actual API key\n",
    "\n",
    "# Initialize the ChatGroq interface\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "# Path to your structured PDF data\n",
    "pdf_file_path = \"data.pdf\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Read and Process Structured PDF Data\n",
    "# -----------------------------\n",
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\" Extract text from the PDF while preserving structure. \"\"\"\n",
    "    pdf_text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                pdf_text += page_text + \"\\n\"\n",
    "    return pdf_text\n",
    "\n",
    "def structure_text(text):\n",
    "    \"\"\" Processes the text into structured sections. \"\"\"\n",
    "    sections = text.split(\"\\n# \")  # Splitting by headers\n",
    "    documents = {}\n",
    "    for section in sections:\n",
    "        lines = section.split(\"\\n\")\n",
    "        title = lines[0].strip()\n",
    "        content = \"\\n\".join(lines[1:]).strip()\n",
    "        if title and content:\n",
    "            documents[title] = content\n",
    "    return documents\n",
    "\n",
    "# Load and process the PDF\n",
    "pdf_text = load_pdf_text(pdf_file_path)\n",
    "structured_data = structure_text(pdf_text)\n",
    "\n",
    "print(\"Structured sections extracted:\", len(structured_data))\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Create FAISS Index for Efficient Search\n",
    "# -----------------------------\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Prepare document keys and embeddings\n",
    "document_keys = list(structured_data.keys())\n",
    "document_texts = [structured_data[key] for key in document_keys]\n",
    "doc_embeddings = embedder.encode(document_texts, convert_to_numpy=True)\n",
    "\n",
    "# Create a FAISS index\n",
    "embedding_dim = doc_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(doc_embeddings)\n",
    "print(\"FAISS index built with\", index.ntotal, \"documents.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Build the RAG Pipeline (with Token Limit Handling)\n",
    "# -----------------------------\n",
    "MAX_CONTEXT_LENGTH = 5000  # Limit to avoid API token limits\n",
    "\n",
    "def build_prompt(query, top_k=5):\n",
    "    \"\"\" Retrieves the most relevant documents and builds a prompt. \"\"\"\n",
    "    query_embedding = embedder.encode(query, convert_to_numpy=True)\n",
    "    distances, indices = index.search(np.array([query_embedding]), top_k)\n",
    "    \n",
    "    retrieved_sections = [document_keys[i] + \":\\n\" + document_texts[i] for i in indices[0]]\n",
    "\n",
    "    # Combine retrieved documents while ensuring token limit\n",
    "    context = \"\\n\\n\".join(retrieved_sections)\n",
    "    if len(context) > MAX_CONTEXT_LENGTH:\n",
    "        context = context[:MAX_CONTEXT_LENGTH]  # Truncate excess text\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a highly factual AI assistant. Use only the provided context to answer accurately.\n",
    "    Do NOT add false information. If details are missing, state only the available data.\n",
    "    \n",
    "    Context:\\n{context}\\n\\n\n",
    "    Question: {query}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Test the RAG Chatbot with Improved Handling\n",
    "# -----------------------------\n",
    "query = \"Can you tell me about vivek ?\"\n",
    "\n",
    "# Build the optimized prompt\n",
    "prompt = build_prompt(query, top_k=5)\n",
    "print(\"=== Optimized Prompt Sent to Model ===\")\n",
    "print(prompt)\n",
    "\n",
    "# Call the model\n",
    "response = llm.invoke(prompt)\n",
    "print(\"\\n=== Generated Answer ===\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1ccff-a590-429d-bd47-0fe7cc33ed92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
